##  Objetivo:
Entender como a previsÃ£o do prÃ³ximo token funciona
sem redes neurais.

Ideia:
Contar quais palavras costumam vir depois de outras.

Aprendizado:
Mesmo sem "inteligÃªncia", padrÃµes emergem.

## ğŸ‘‰ escrever um script que:
recebe um texto de treino
constrÃ³i uma tabela:

```bash
palavra_atual -> {proxima_palavra: contagem}
```

## dado um token, prevÃª o prÃ³ximo

next_token_model.py ==> â€œcÃ©rebro primitivoâ€